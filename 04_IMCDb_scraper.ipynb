{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframe of results with today's date\n",
    "today = date.today()\n",
    "d_today = today.strftime(\"%Y_%m_%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation for Scrape Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100df = pd.read_csv(\"output_data/Top100_Movies_2010-2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n"
     ]
    }
   ],
   "source": [
    "# create list of years\n",
    "years = top_100df[\"Year\"].unique().tolist()\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2010: [], 2011: [], 2012: [], 2013: [], 2014: [], 2015: [], 2016: [], 2017: [], 2018: [], 2019: [], 2020: [], 2021: []}\n"
     ]
    }
   ],
   "source": [
    "# use a dictionary to create multiple empty lists to store each  year's top 100 movies\n",
    "obj = {}\n",
    "for year in years:\n",
    "    obj[year] = []\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the year of movies we are scraping data for; each year is done individually for quality control\n",
    "scrape_year = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bad Boys for Life', '1917', 'Sonic the Hedgehog', 'Jumanji: The Next Level', 'Star Wars: Episode IX - The Rise of Skywalker', 'Birds of Prey', 'Dolittle', 'Little Women', 'The Invisible Man', 'The Call of the Wild', 'Onward', 'Knives Out', 'Frozen II', 'Tenet', 'Spies in Disguise', 'The Gentlemen', 'Just Mercy', 'The Croods: A New Age', 'Parasite', 'Fantasy Island', 'Uncut Gems', 'The New Mutants', 'Like a Boss', 'The Grudge', 'Unhinged', 'The Photograph', 'The War with Grandpa', 'Underwater', 'Wonder Woman 1984', 'The Turning', 'Gretel & Hansel', 'Honest Thief', 'My Hero Academia: Heroes Rising', 'Bombshell', 'The Way Back', 'Brahms: The Boy II', 'Jojo Rabbit', 'Impractical Jokers: The Movie', 'Ford v Ferrari', 'Emma.', 'Bloodshot', 'I Still Believe', 'Come Play', 'Let Him Go', 'Freaky', 'Downhill', 'Weathering with You', 'Cats', 'The Hunt', 'The Rhythm Section', 'Monster Hunter', 'A Beautiful Day in the Neighborhood', 'Hocus Pocus2020 Re-release', 'Richard Jewell', 'The SpongeBob Movie: Sponge on the Run', 'The Broken Hearts Gallery', 'Infidel', 'News of the World', 'Portrait of a Lady on Fire', 'Bill & Ted Face the Music', '2020 Oscar Nominated Short Films', 'Queen & Slim', 'The Empty Man', \"My Boyfriend's Meds\", 'The Last Full Measure', 'Words on Bathroom Walls', 'Star Wars: Episode V - The Empire Strikes Back2020 Re-release', 'Fatale', 'The Nightmare Before Christmas2020 Re-release', 'Ip Man 4: The Finale', 'Half Brothers', 'Elf2020 Re-release', 'The Personal History of David Copperfield', 'The Wretched', 'The Lodge', 'Joker', 'The Rental', 'Once Upon a Time... In Hollywood', 'Jurassic Park2020 Re-release', '2 Hearts', 'Promising Young Woman', 'True to the Game 2', 'Train to Busan Presents: Peninsula', 'The Assistant', 'Love and Monsters', 'Relic', 'The Tax Collector', 'The Last Shift', 'Becky', 'The Song of Names', 'All My Life', 'Mafia Inc', \"National Lampoon's Christmas Vacation2020 Re-release\", 'Jay and Silent Bob Reboot', 'A Hidden Life', 'Cut Throat City', 'The Goonies2020 Re-release', 'Sarileru Neekevvaru', 'Vanguard', 'Shortcut']\n"
     ]
    }
   ],
   "source": [
    "# fill dictionary with lists of the top 100 movies per year, display a sample year\n",
    "for year in obj:\n",
    "    top_100 = top_100df.loc[top_100df[\"Year\"] == year]\n",
    "    obj[year] = top_100[\"Release\"].tolist()\n",
    "print(obj[scrape_year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Function Executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n",
      "[WDM] - Driver [C:\\Users\\stuhu\\.wdm\\drivers\\chromedriver\\win32\\89.0.4389.23\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "# setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imcdb.org/\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_mov(titles):\n",
    "    movie_dict = {}\n",
    "    for title in titles:\n",
    "        movie_dict[title] = []\n",
    "    for title in titles:\n",
    "                \n",
    "        print(f\"Processing {title}...\")\n",
    "        \n",
    "        browser.find_by_css('input').fill(title)\n",
    "        time.sleep(1)\n",
    "        browser.find_by_value('Search').click()\n",
    "        time.sleep(5)\n",
    "    \n",
    "        html = browser.html\n",
    "        soup = bs(html, 'html.parser')\n",
    "    \n",
    "        results = soup.find_all('div', class_='ThumbnailBox')\n",
    "        if len(results) != 0:\n",
    "            good = 1\n",
    "        else:\n",
    "            good = 0\n",
    "            try:\n",
    "                browser.links.find_by_text(title).click()\n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                print(\"No data for the movie.\")\n",
    "                good = 0\n",
    "                continue\n",
    "        \n",
    "        if good == 1:\n",
    "            good2 = 1\n",
    "        else:\n",
    "            html = browser.html\n",
    "            soup = bs(html, 'html.parser')\n",
    "            results = soup.find_all('div', class_='ThumbnailBox')\n",
    "            if len(results) != 0:\n",
    "                good2 = 1\n",
    "            else:\n",
    "                good2 = 0\n",
    "                print(\"Not good at all: no car data.\")\n",
    "                continue\n",
    "        \n",
    "        if good2 == 1:\n",
    "            print(\"Car data collected.\")\n",
    "            count = 0\n",
    "            for result in results:\n",
    "                try:\n",
    "                    x = result.find('span', class_='Stars')\n",
    "                    y = len(x)\n",
    "                    z = result.find('a')['href']\n",
    "                    info_string = result.text\n",
    "                    count += 1\n",
    "                    movie_dict[title].append([count, info_string, z, y])\n",
    "                except:\n",
    "                    y = 'Nan'\n",
    "                    z = result.find('a')['href']\n",
    "                    info_string = result.text\n",
    "                    count += 1\n",
    "                    movie_dict[title].append([count, info_string, z, y])\n",
    "        else:\n",
    "            pass\n",
    "    browser.quit()\n",
    "    print(\"Scraping completed.\")\n",
    "    return movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Bad Boys for Life...\n",
      "Car data collected.\n",
      "Processing 1917...\n",
      "Car data collected.\n",
      "Processing Sonic the Hedgehog...\n",
      "Car data collected.\n",
      "Processing Jumanji: The Next Level...\n",
      "Car data collected.\n",
      "Processing Star Wars: Episode IX - The Rise of Skywalker...\n",
      "Car data collected.\n",
      "Processing Birds of Prey...\n",
      "Car data collected.\n",
      "Processing Dolittle...\n",
      "No data for the movie.\n",
      "Processing Little Women...\n",
      "No data for the movie.\n",
      "Processing The Invisible Man...\n",
      "Car data collected.\n",
      "Processing The Call of the Wild...\n",
      "No data for the movie.\n",
      "Processing Onward...\n",
      "Car data collected.\n",
      "Processing Knives Out...\n",
      "Car data collected.\n",
      "Processing Frozen II...\n",
      "No data for the movie.\n",
      "Processing Tenet...\n",
      "Car data collected.\n",
      "Processing Spies in Disguise...\n",
      "Car data collected.\n",
      "Processing The Gentlemen...\n",
      "Car data collected.\n",
      "Processing Just Mercy...\n",
      "Car data collected.\n",
      "Processing The Croods: A New Age...\n",
      "No data for the movie.\n",
      "Processing Parasite...\n",
      "Car data collected.\n",
      "Processing Fantasy Island...\n",
      "Car data collected.\n",
      "Processing Uncut Gems...\n",
      "Car data collected.\n",
      "Processing The New Mutants...\n",
      "No data for the movie.\n",
      "Processing Like a Boss...\n",
      "Car data collected.\n",
      "Processing The Grudge...\n",
      "Car data collected.\n",
      "Processing Unhinged...\n",
      "Car data collected.\n",
      "Processing The Photograph...\n",
      "No data for the movie.\n",
      "Processing The War with Grandpa...\n",
      "Car data collected.\n",
      "Processing Underwater...\n",
      "Car data collected.\n",
      "Processing Wonder Woman 1984...\n",
      "Car data collected.\n",
      "Processing The Turning...\n",
      "Car data collected.\n",
      "Processing Gretel & Hansel...\n",
      "No data for the movie.\n",
      "Processing Honest Thief...\n",
      "Car data collected.\n",
      "Processing My Hero Academia: Heroes Rising...\n",
      "Car data collected.\n",
      "Processing Bombshell...\n",
      "Car data collected.\n",
      "Processing The Way Back...\n",
      "No data for the movie.\n",
      "Processing Brahms: The Boy II...\n",
      "No data for the movie.\n",
      "Processing Jojo Rabbit...\n",
      "Car data collected.\n",
      "Processing Impractical Jokers: The Movie...\n",
      "No data for the movie.\n",
      "Processing Ford v Ferrari...\n",
      "Car data collected.\n",
      "Processing Emma....\n",
      "No data for the movie.\n",
      "Processing Bloodshot...\n",
      "Car data collected.\n",
      "Processing I Still Believe...\n",
      "No data for the movie.\n",
      "Processing Come Play...\n",
      "No data for the movie.\n",
      "Processing Let Him Go...\n",
      "No data for the movie.\n",
      "Processing Freaky...\n",
      "No data for the movie.\n",
      "Processing Downhill...\n",
      "Car data collected.\n",
      "Processing Weathering with You...\n",
      "No data for the movie.\n",
      "Processing Cats...\n",
      "Car data collected.\n",
      "Processing The Hunt...\n",
      "Car data collected.\n",
      "Processing The Rhythm Section...\n",
      "Car data collected.\n",
      "Processing Monster Hunter...\n",
      "Car data collected.\n",
      "Processing A Beautiful Day in the Neighborhood...\n",
      "Car data collected.\n",
      "Processing Hocus Pocus2020 Re-release...\n",
      "No data for the movie.\n",
      "Processing Richard Jewell...\n",
      "Car data collected.\n",
      "Processing The SpongeBob Movie: Sponge on the Run...\n",
      "No data for the movie.\n",
      "Processing The Broken Hearts Gallery...\n",
      "No data for the movie.\n",
      "Processing Infidel...\n",
      "No data for the movie.\n",
      "Processing News of the World...\n",
      "No data for the movie.\n",
      "Processing Portrait of a Lady on Fire...\n",
      "No data for the movie.\n",
      "Processing Bill & Ted Face the Music...\n",
      "Car data collected.\n",
      "Processing 2020 Oscar Nominated Short Films...\n",
      "No data for the movie.\n",
      "Processing Queen & Slim...\n",
      "Car data collected.\n",
      "Processing The Empty Man...\n",
      "No data for the movie.\n",
      "Processing My Boyfriend's Meds...\n",
      "No data for the movie.\n",
      "Processing The Last Full Measure...\n",
      "No data for the movie.\n",
      "Processing Words on Bathroom Walls...\n",
      "No data for the movie.\n",
      "Processing Star Wars: Episode V - The Empire Strikes Back2020 Re-release...\n",
      "No data for the movie.\n",
      "Processing Fatale...\n",
      "Car data collected.\n",
      "Processing The Nightmare Before Christmas2020 Re-release...\n",
      "No data for the movie.\n",
      "Processing Ip Man 4: The Finale...\n",
      "No data for the movie.\n",
      "Processing Half Brothers...\n",
      "No data for the movie.\n",
      "Processing Elf2020 Re-release...\n",
      "No data for the movie.\n",
      "Processing The Personal History of David Copperfield...\n",
      "No data for the movie.\n",
      "Processing The Wretched...\n",
      "No data for the movie.\n",
      "Processing The Lodge...\n",
      "Car data collected.\n",
      "Processing Joker...\n",
      "Car data collected.\n",
      "Processing The Rental...\n",
      "No data for the movie.\n",
      "Processing Once Upon a Time... In Hollywood...\n",
      "Car data collected.\n",
      "Processing Jurassic Park2020 Re-release...\n",
      "No data for the movie.\n",
      "Processing 2 Hearts...\n",
      "No data for the movie.\n",
      "Processing Promising Young Woman...\n",
      "No data for the movie.\n",
      "Processing True to the Game 2...\n",
      "No data for the movie.\n",
      "Processing Train to Busan Presents: Peninsula...\n",
      "No data for the movie.\n",
      "Processing The Assistant...\n",
      "Car data collected.\n",
      "Processing Love and Monsters...\n",
      "No data for the movie.\n",
      "Processing Relic...\n",
      "Car data collected.\n",
      "Processing The Tax Collector...\n",
      "Car data collected.\n",
      "Processing The Last Shift...\n",
      "No data for the movie.\n",
      "Processing Becky...\n",
      "No data for the movie.\n",
      "Processing The Song of Names...\n",
      "No data for the movie.\n",
      "Processing All My Life...\n",
      "No data for the movie.\n",
      "Processing Mafia Inc...\n",
      "Car data collected.\n",
      "Processing National Lampoon's Christmas Vacation2020 Re-release...\n",
      "No data for the movie.\n",
      "Processing Jay and Silent Bob Reboot...\n",
      "Car data collected.\n",
      "Processing A Hidden Life...\n",
      "No data for the movie.\n",
      "Processing Cut Throat City...\n",
      "Car data collected.\n",
      "Processing The Goonies2020 Re-release...\n",
      "No data for the movie.\n",
      "Processing Sarileru Neekevvaru...\n",
      "No data for the movie.\n",
      "Processing Vanguard...\n",
      "Car data collected.\n",
      "Processing Shortcut...\n",
      "No data for the movie.\n",
      "Scraping completed.\n"
     ]
    }
   ],
   "source": [
    "# create our dictionary of car data\n",
    "top_year = obj[scrape_year]\n",
    "top_yearcars = car_mov(top_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification\n",
    "print(top_yearcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export/Import Scraped Data for backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(top_yearcars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing dictionary to text file\n",
    "try:\n",
    "    file_dict = open(f\"top_{scrape_year}cars.txt\", 'wt')\n",
    "    file_dict.write(str(top_yearcars))\n",
    "    file_dict.close()\n",
    "except: \n",
    "    print(\"Unable to write to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable to write a file? Try this instead, otherwise skip this\n",
    "file_dict = open(f\"top_{scrape_year}cars.txt\", 'wt', encoding=\"utf-8\")\n",
    "file_dict.write(str(top_yearcars))\n",
    "file_dict.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dictionary from text file back\n",
    "file = open(f\"top_{scrape_year}cars.txt\", \"r\")\n",
    "contents = file.read()\n",
    "data = ast.literal_eval(contents)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Missing Data Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\stuhu\\.wdm\\drivers\\chromedriver\\win32\\89.0.4389.23\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imcdb.org/\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart Manual Scrape Here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scrape data for a single film\n",
    "def cars_manual(movie):\n",
    "    print(f\"Processing {movie}...\")\n",
    "    missing = f\"{movie}\"\n",
    "    miss_dict = {}\n",
    "    miss_dict[missing] = []\n",
    "\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    \n",
    "    results = soup.find_all('div', class_='ThumbnailBox')\n",
    "    if len(results) != 0:\n",
    "        good = 1\n",
    "    else:\n",
    "        good = 0\n",
    "        try:\n",
    "            browser.links.find_by_text(missing).click()\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(\"No data for the movie.\")\n",
    "            good = 0\n",
    "        \n",
    "    if good == 1:\n",
    "        good2 = 1\n",
    "    else:\n",
    "        html = browser.html\n",
    "        soup = bs(html, 'html.parser')\n",
    "        results = soup.find_all('div', class_='ThumbnailBox')\n",
    "        if len(results) != 0:\n",
    "            good2 = 1\n",
    "        else:\n",
    "            good2 = 0\n",
    "            print(\"Not good at all: no car data.\")\n",
    "\n",
    "    if good2 == 1:\n",
    "        print(\"Data collected.\")\n",
    "        count = 0\n",
    "        for result in results:\n",
    "            try:\n",
    "                x = result.find('span', class_='Stars')\n",
    "                y = len(x)\n",
    "                z = result.find('a')['href']\n",
    "                info_string = result.text\n",
    "                count += 1\n",
    "                miss_dict[missing].append([count, info_string, z, y])\n",
    "            except:\n",
    "                y = 'Nan'\n",
    "                z = result.find('a')['href']\n",
    "                info_string = result.text\n",
    "                count += 1\n",
    "                miss_dict[missing].append([count, info_string, z, y])\n",
    "    else:\n",
    "        pass\n",
    "    return miss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to delete a single film's car data from our dictionary\n",
    "def delete_data(movie):\n",
    "    # remove data if no substitute can be manually found\n",
    "    del top_yearcars[movie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Birds of Prey\n",
      "Processing Birds of Prey...\n",
      "Data collected.\n",
      "First car: [1, '2000 Bentley Arnage Red Label ', 'vehicle_1370146-Bentley-Arnage-Red-Label-2000.html', 2]\n",
      "Last car: [65, '1971 Winnebago Brave ', 'vehicle_1370155-Winnebago-Brave-1971.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):The Invisible Man\n",
      "Processing The Invisible Man...\n",
      "Data collected.\n",
      "First car: [1, '1974 AMC Gremlin ', 'vehicle_1366859-AMC-Gremlin-1974.html', 1]\n",
      "Last car: [26, '2009 Yamaha VMX 1700 V-Max ', 'vehicle_1316641-Yamaha-VMX-1700-V-Max-2009.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Parasite\n",
      "Processing Parasite...\n",
      "Data collected.\n",
      "First car: [1, '2014 Audi A8 D4 ', 'vehicle_1341223-Audi-A8-Typ-4H-2014.html', 1]\n",
      "Last car: [14, '2011 Porsche Cayenne [958] ', 'vehicle_1341237-Porsche-Cayenne-958-2011.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Fantasy Island\n",
      "Processing Fantasy Island...\n",
      "Data collected.\n",
      "First car: [1, '2007 Hummer H3 ', 'vehicle_1374583-Hummer-H3-GMT345-2007.html', 1]\n",
      "Last car: [5, '2016 Toyota RAV4 ', 'vehicle_1374588-Toyota-RAV4-XA40-2016.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):The Grudge\n",
      "Processing The Grudge...\n",
      "Data collected.\n",
      "First car: [1, '1976 Cadillac Fleetwood 60 Special Brougham ', 'vehicle_1408327-Cadillac-Fleetwood-60-Special-Brougham-1976.html', 1]\n",
      "Last car: [11, '1984 unknown ', 'vehicle_1408328-1984.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Unhinged\n",
      "Processing Unhinged...\n",
      "Data collected.\n",
      "First car: [1, '2019 Acura RDX ', 'vehicle_1451642-Acura-RDX-TC-2019.html', 1]\n",
      "Last car: [117, '1995 Volvo 960 ', 'vehicle_1387504-Volvo-960-965-1995.html', 4]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: delete\n",
      "Title of the movie (exact upper and lower cases):The Turning\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: delete\n",
      "Title of the movie (exact upper and lower cases):Underwater\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Bombshell\n",
      "Processing Bombshell...\n",
      "Data collected.\n",
      "First car: [1, '2016 BMW X1 [F48] ', 'vehicle_1356222-BMW-X1-F48-2016.html', 1]\n",
      "Last car: [14, '2014 Volvo XC60 ', 'vehicle_1356219-Volvo-XC60-2014.html', 2]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: delete\n",
      "Title of the movie (exact upper and lower cases):Downhill\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):The Hunt\n",
      "Processing The Hunt...\n",
      "Data collected.\n",
      "First car: [1, 'AM General HMMWV M1037 ', 'vehicle_1369848-AM-General-HMMWV-M1037.html', 1]\n",
      "Last car: [5, 'Stewart & Stevenson M1078 LMTV ', 'vehicle_1369726-Stewart-and-Stevenson-M1078-LMTV.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):The Lodge\n",
      "Processing The Lodge...\n",
      "Data collected.\n",
      "First car: [1, '2006 Audi A3 ', 'vehicle_1424050-Audi-A3-Typ-8PA-2006.html', 3]\n",
      "Last car: [4, 'Porsche Cayenne [958] ', 'vehicle_1424051-Porsche-Cayenne-958.html', 1]\n",
      "Do we still have a movie to update? (yes/no): yes\n",
      "Do we want to update or delete data?: update\n",
      "Title of the movie (exact upper and lower cases):Joker\n",
      "Processing Joker...\n",
      "Data collected.\n",
      "First car: [1, '1985 BMW 3 [E30] ', 'vehicle_1339518-BMW-3-E30-1985.html', 1]\n",
      "Last car: [35, '1972 Volkswagen Sedan [Typ 1] ', 'vehicle_1295614-Volkswagen-Sedan-Typ-1-1972.html', 1]\n",
      "Do we still have a movie to update? (yes/no): no\n",
      "Manual updates completed.\n"
     ]
    }
   ],
   "source": [
    "# while loop to manually update or delete films that were not scraped properly\n",
    "answer = \"yes\"\n",
    "while answer == \"yes\":\n",
    "    decision = input(\"Do we want to update or delete data?: \").lower()\n",
    "    if decision == \"update\":\n",
    "        title = input(\"Title of the movie (exact upper and lower cases):\")\n",
    "        new_dict = cars_manual(title)\n",
    "        # use update method to update value of errant key/title data\n",
    "        top_yearcars.update(new_dict)\n",
    "        # verification\n",
    "        print(f\"First car: {top_yearcars[title][0]}\")\n",
    "        print(f\"Last car: {top_yearcars[title][-1]}\")\n",
    "        # outgoing exit option\n",
    "        answer = input(\"Do we still have a movie to update? (yes/no): \").lower()\n",
    "    elif decision == \"delete\":\n",
    "        title = input(\"Title of the movie (exact upper and lower cases):\")\n",
    "        delete_data(title)\n",
    "        answer = input(\"Do we still have a movie to update? (yes/no): \").lower()\n",
    "    else:\n",
    "        answer = \"no\"\n",
    "print(\"Manual updates completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_yearcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cars for the movie, Underwater.\n",
      "No cars for the movie, The Turning.\n",
      "No cars for the movie, Downhill.\n"
     ]
    }
   ],
   "source": [
    "# create dataframe of data for each vehicle, with movie and movie year included\n",
    "title = []\n",
    "year = []\n",
    "auto = []\n",
    "link = []\n",
    "stars = []\n",
    "for movie in top_year:\n",
    "    try:\n",
    "        cars = top_yearcars[movie]\n",
    "        for car in cars:\n",
    "            title.append(movie)\n",
    "            year.append(scrape_year)\n",
    "            auto.append(car[1])\n",
    "            link.append(car[2])\n",
    "            stars.append(car[3])\n",
    "    except:\n",
    "        print(f\"No cars for the movie, {movie}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_year_df = pd.DataFrame({\"Release\": title, \"Year\": year, \"Car\": auto, \"url\": link, \"Stars\": stars})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release</th>\n",
       "      <th>Year</th>\n",
       "      <th>Car</th>\n",
       "      <th>url</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad Boys for Life</td>\n",
       "      <td>2020</td>\n",
       "      <td>2007 BAE Systems Caiman CMTV</td>\n",
       "      <td>vehicle_1368488-BAE-Systems-Caiman-CMTV-2007.html</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad Boys for Life</td>\n",
       "      <td>2020</td>\n",
       "      <td>2006 BMW 3 [E90]</td>\n",
       "      <td>vehicle_1368485-BMW-3-E90-2006.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad Boys for Life</td>\n",
       "      <td>2020</td>\n",
       "      <td>2004 BMW 5 [E60]</td>\n",
       "      <td>vehicle_1368481-BMW-5-E60-2004.html</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad Boys for Life</td>\n",
       "      <td>2020</td>\n",
       "      <td>BMW M6 [E63]</td>\n",
       "      <td>vehicle_1368482-BMW-M6-E63.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad Boys for Life</td>\n",
       "      <td>2020</td>\n",
       "      <td>2003 Buick Century</td>\n",
       "      <td>vehicle_1368473-Buick-Century-2003.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>Vanguard</td>\n",
       "      <td>2020</td>\n",
       "      <td>2007 Volvo S60</td>\n",
       "      <td>vehicle_1447514-Volvo-S60-2007.html</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>Vanguard</td>\n",
       "      <td>2020</td>\n",
       "      <td>2015 Volvo XC90</td>\n",
       "      <td>vehicle_1447734-Volvo-XC90-2015.html</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>Vanguard</td>\n",
       "      <td>2020</td>\n",
       "      <td>2013 WaterCar Panther</td>\n",
       "      <td>vehicle_1447595-WaterCar-Panther-2013.html</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>Vanguard</td>\n",
       "      <td>2020</td>\n",
       "      <td>2012 Wright New Routemaster</td>\n",
       "      <td>vehicle_1447645-Wright-New-Routemaster-2012.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>Vanguard</td>\n",
       "      <td>2020</td>\n",
       "      <td>2003 Yamaha YZF-R6</td>\n",
       "      <td>vehicle_1447616-Yamaha-YZF-R6-2003.html</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1422 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Release  Year                            Car  \\\n",
       "0     Bad Boys for Life  2020  2007 BAE Systems Caiman CMTV    \n",
       "1     Bad Boys for Life  2020              2006 BMW 3 [E90]    \n",
       "2     Bad Boys for Life  2020              2004 BMW 5 [E60]    \n",
       "3     Bad Boys for Life  2020                  BMW M6 [E63]    \n",
       "4     Bad Boys for Life  2020            2003 Buick Century    \n",
       "...                 ...   ...                            ...   \n",
       "1417           Vanguard  2020                2007 Volvo S60    \n",
       "1418           Vanguard  2020               2015 Volvo XC90    \n",
       "1419           Vanguard  2020         2013 WaterCar Panther    \n",
       "1420           Vanguard  2020   2012 Wright New Routemaster    \n",
       "1421           Vanguard  2020            2003 Yamaha YZF-R6    \n",
       "\n",
       "                                                    url Stars  \n",
       "0     vehicle_1368488-BAE-Systems-Caiman-CMTV-2007.html     2  \n",
       "1                   vehicle_1368485-BMW-3-E90-2006.html     1  \n",
       "2                   vehicle_1368481-BMW-5-E60-2004.html     2  \n",
       "3                       vehicle_1368482-BMW-M6-E63.html     1  \n",
       "4               vehicle_1368473-Buick-Century-2003.html     1  \n",
       "...                                                 ...   ...  \n",
       "1417                vehicle_1447514-Volvo-S60-2007.html     2  \n",
       "1418               vehicle_1447734-Volvo-XC90-2015.html     3  \n",
       "1419         vehicle_1447595-WaterCar-Panther-2013.html     3  \n",
       "1420   vehicle_1447645-Wright-New-Routemaster-2012.html     1  \n",
       "1421            vehicle_1447616-Yamaha-YZF-R6-2003.html     3  \n",
       "\n",
       "[1422 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export as csv for use elsewhere\n",
    "top_year_df.to_csv(f\"output_data/{d_today}_{scrape_year}Cars.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
